{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2. Кластеризация (KMeans)\n",
    "1. Сгенерировать подходящие исходные данные для проведения обучения\n",
    "2. Провести кластеризацию с помощью pyspark.ml / pyspark.mllib\n",
    "3. Вывести и сохранить в файл полученные центры кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сгенерировать подходящие исходные данные для проведения обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"D:/BigData/spark-3.5.3\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "\n",
    "samples=500\n",
    "centers=4\n",
    "features=2\n",
    "\n",
    "\n",
    "X, y = make_blobs(n_samples=samples, n_features=features, centers=centers, cluster_std=1, random_state=42)\n",
    "\n",
    "# Формирование исходного датафрейма\n",
    "data = pd.DataFrame(X, columns=[\"feature1\", \"feature2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Провести кластеризацию с помощью pyspark.ml / pyspark.mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Создание SparkSession\n",
    "spark = SparkSession.builder.appName(\"KMeans\").getOrCreate()\n",
    "\n",
    "# Формируем dataframe\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Векторизуем данные для обучения \n",
    "vector_assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\n",
    "df = vector_assembler.transform(df)\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "kmeans = KMeans().setK(centers).setSeed(1)\n",
    "model = kmeans.fit(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывести и сохранить в файл полученные центры кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+----------+\n",
      "|           feature1|            feature2|            features|prediction|\n",
      "+-------------------+--------------------+--------------------+----------+\n",
      "|-7.6890544303503345|   6.620346490372816|[-7.6890544303503...|         1|\n",
      "| -9.576513834092841|  -6.934404459793758|[-9.5765138340928...|         2|\n",
      "|  6.829681769445774|  1.1648713985855805|[6.82968176944577...|         0|\n",
      "|-2.9013057761849077|   7.550771180066203|[-2.9013057761849...|         3|\n",
      "| -5.678413268987326|  -7.288184966297498|[-5.6784132689873...|         2|\n",
      "| -6.049291374607025|  -7.736193419184814|[-6.0492913746070...|         2|\n",
      "| -6.278243218367216|   7.227463015774053|[-6.2782432183672...|         1|\n",
      "|-6.6091703653714315|  -6.930347702725084|[-6.6091703653714...|         2|\n",
      "|  3.572258406845507|  1.8307901989194386|[3.57225840684550...|         0|\n",
      "| -7.504445768846949|  -6.854018543065113|[-7.5044457688469...|         2|\n",
      "| 3.9933059519855747|   0.891621680326337|[3.99330595198557...|         0|\n",
      "|-1.3506020440453461|    8.19360380984661|[-1.3506020440453...|         3|\n",
      "|  6.772912210884368|0.021081884418230112|[6.77291221088436...|         0|\n",
      "|-1.9383071123595832|   10.14985176837892|[-1.9383071123595...|         3|\n",
      "| -6.589852334254857|  -4.804708794630508|[-6.5898523342548...|         2|\n",
      "|  5.698303323077689| 0.21443019751761772|[5.69830332307768...|         0|\n",
      "| -2.581207744633084|  10.017819026090345|[-2.5812077446330...|         3|\n",
      "| -9.961049778198309|   7.705932661682754|[-9.9610497781983...|         1|\n",
      "| -8.756043767360586|   8.389003290564055|[-8.7560437673605...|         1|\n",
      "|-3.6155325970587784|   7.818079504117651|[-3.6155325970587...|         3|\n",
      "+-------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Предсказываем кластеры\n",
    "markers = model.transform(df)\n",
    "\n",
    "# Сохраняем в файл полученные данные\n",
    "pd_markers = markers.toPandas()\n",
    "pd_markers.to_json(\"centers_claster.json\", orient='records', lines=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
